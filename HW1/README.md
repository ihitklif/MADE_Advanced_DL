#### Advanced DL and RL: Домашнее задание 1
#### ФИО: Kaledin Artem
#### Группа: DS-31

Структура проекта 

* envs — окружения

  * gym-foo — пример окружения для импорта в gym (в частности, для double)
  
  Окружения для различных частей задания
  
  * pt2_env_double.py — с double
  
  * pt3_env_count_cards.py — с подсчетом карт
  
  * pt4_split.py — со split-ом
  
* draws — визуализация наград за игры

  * All_graphics.* — содержит все графики по частям задания

* Ноутбуки с выполненными частями HW1_DL_Blackjack_Task_*.ipynb

##### Task 1:
##### Стартовая инициализация алгоритмов на Блекджеке из коробки gym
* Решение в виде ноутбука — HW1_DL_Blackjack_Task_1.ipynb
* Здесь и далее награды считаются на моделировании игр после обучения на 10к/20к/... итераций


##### Task 2:
##### Добавлен double
* MC Control показал себя лучше
* Q-learning показал себя лучше
* Решение в виде ноутбука — HW1_DL_Blackjack_Task_2.ipynb

##### Task 3:
##### Добавлен подсчет карт в колоде по системе «Половинки»
* MC Control стал хуже
* Q-learning показал себя чуть лучше
* Решение в виде ноутбука — HW1_DL_Blackjack_Task_3.ipynb

##### Task 4:
##### Реализуйте вариант из третьей части, в котором есть ещё возможность делать split
* Split реализован в envs/pt4_split.py
* Реализация добавляет нового игрока и разрешает разово делать сплит при совпадающих картах в руке игрока на раздаче
* В стратегии получилось выйти в "+" (!)
* Решение в виде ноутбука — HW1_DL_Blackjack_Task_4.ipynb

##### Task 5:
##### Реализуйте поиск стратегии в блекджеке с известной моделью из первой части, решив уравнения Беллмана для V* или Q*.
* Вероятности рассчитаны с помощью генерации 500_000 игр с последующим подсчетом переходов из состояния в состояние и наград 
  (то есть знаем p(s', r | s,a) и rewards.
* Далее с помощью Policy evaluation находим V*.
* Решение в виде ноутбука — HW1_DL_Blackjack_Task_5.ipynb
